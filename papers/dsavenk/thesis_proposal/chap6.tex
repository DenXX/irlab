% chap6.tex
%

\mychapter{Summary and Discussion}
\label{chapter:discussion}

\noindent

In my thesis I propose several pieces of work towards improving user satisfaction with question answering systems.
I plan to consider factoid and non-factoid questions, as usually classified in the community, separately, because certain techniques and data sources are most useful for one type of questions and not another.

The research I'm propose to conduct for improving factoid question answering targets a problem of combining information available in different data sources, \ie structured knowledge bases and unstructured text documents.
Semantic annotations of entity mentions in documents create additional connections between knowledge base entities, which should improve KB coverage and allow a system to answer more questions and with better precision.
However, such an approach have certain potential limitations.
\begin{itemize}
\item A set of additional links for some entities is likely to be big, which makes it impossible to explore them all. Information extraction approaches on the other hand aggregate information over the whole collection, although the extraction process itself brings extra noise.
\item ....
\end{itemize}

For non-factoid question answering I propose several improvements, targeting different stages of the question answering process.
Question to query generation neural network model, trained to improve the document retrieval performance, should increase the recall of the question answering system by identifying the key phrases that needed to be search for.
The answer passage scoring module should achieve a better precision by analyzing the structure of the answer origin web page, and detecting question-answer pairs and other key structural elements.
Finally, the proposed direction in automatic answer summarization is a way to increase the quality of answers by combining evidence from multiple different data sources, possibly providing additional information and alternative opinions.
Possible limitations of the proposed directions and approaches are:
\begin{itemize}
\item question to query generation model can be retrieval engine specific, which may force the model to be retrained after certain changes in the retrieval algorithm. An alternative strategy is to integrate a similar question summarization module into the retrieval engine itself.
\item web page structure?...
\item summarization?... The problem is that it might not work well...
\end{itemize}

Finally, I touch a user aspect of question answering, in particular user assistance with hints in case a system failed to respond to user information needs, clarification questions, which is one of the first steps in dialog-based question answering and finally using the wisdom of a crowd to improve the performance of question answering systems.
\begin{itemize}
\item Hints 
\item Clarifications
\item Crowdsourcing
\end{itemize}
