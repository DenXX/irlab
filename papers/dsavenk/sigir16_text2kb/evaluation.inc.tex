
The experiments in this work were conducted on WebQuestions dataset, presented in \cite{Berant:EMNLP13}.
Recently, it gained a lot of attention and became the benchmark dataset for KBQA.
The performance of existing systems and our Text2KB is presented in Table \ref{table:webquestions_results}.

\begin{table}
\caption{Performance of the Text2KB system on WebQuestions dataset}
\label{table:webquestions_results}
\begin{tabular}{| p{2.7cm} | c | c | c | c | }
\hline
System & avg Re & avg Pr & F1 of avg & avg F1 \\
\hline
SemPre \cite{Berant:EMNLP13} & 0.413 & 0.480 & 0.444 & 0.357\\
Subgraph Embeddings \cite{BordesCW14:emnlp} & - & - & 0.432 & 0.392\\
ParaSemPre \cite{berant2014semantic} & 0.466 & 0.405 & 0.433 & 0.399\\
Jacana \cite{yao2014information} & 0.458 & 0.517 & 0.486 & 0.330\\
Kitt AI \cite{yao-scratch-qa-naacl2015} & 0.545 & 0.526 & 0.535 & 0.443\\
AgendaIL \cite{berant2015imitation} & 0.557 & 0.505 & 0.530 & 0.497\\
STAGG \cite{yih2015semantic} & 0.607 & 0.528 & 0.565 & 0.525\\
\hline
Our baseline \cite{ACCU:2015} & 0.604 & 0.498 & 0.546 & 0.494\\
Text-only baseline & & & & \\
Text2KB & & & & \\
\hline
\end{tabular}
\end{table}


\subsection{Ablation Study}

To study the effect of different components we made an ablation study, and the results are presented in Table \ref{table:webquestions_ablation}.
The following notations are used to represent different components of our system: T - notable type model, DF - using date range filter, TF - using notable type based filter, E - using web search results to detect question entities, W - using web search snippets and documents features, CQA - using cqa term-relation scores to generate features, CW - using entity pair language model from ClueWeb for feature generation.

\begin{table}
\caption{Ablation study}
\label{table:webquestions_ablation}
\begin{tabular}{| p{4cm} | c | c | c | }
\hline
System & avg Re & avg Pr &  avg F1 \\
\hline
AQQU & 0.604 & 0.498 & 0.494\\
Text2KB -TF & 0.6429 & 0.5030 & 0.5220 \\
\hline
% THIS PART SHOULD ANSWER HOW TEXT BASED FEATURED COMPARE TO EXTERNAL ENTITIES
% web_cqa_clueweb_typemodel_rf100.log : web+cqa+clueweb+typemodel -external-dates
Text2KB +W+CQA+CW+T-E & 0.6351 & 0.4933 & 0.5104 \\
% web_cqa_clueweb_noext_rf100.log : web+cqa+clueweb -external-dates-typemodel
Text2KB +W+CQA+CW-E & 0.6414 & 0.4981 & 0.5160 \\
% typemodel_rf100.log : type model only
Text2KB +T-W-CQA-CL-E &  &  & \\
\hline
\multicolumn{4}{|c|}{Features from which data source are the most useful} \\
\hline
% THIS PART ANSWERS HOW GOOD ARE EACH OF THE PROPOSED DATASETS
% extent_cqa_clueweb_dates_typemodel_rf100.log : -web
Text2KB -W & 0.6327 & 0.4960 & 0.5126 \\
% extent_web_clueweb_dates_typemodel_rf100.log : -cqa
Text2KB -CQA & 0.6420 & 0.4987 & 0.5185 \\
% extent_web_cqa_dates_typemodel_rf100.log : -clueweb
Text2KB -CL & 0.6444 & 0.5047 & 0.5228 \\
\hline
% extent_web_dates_typemodel_rf100.log : -clueweb-cqa
Text2KB -CQA-CL & 0.6423 & 0.5028 & 0.5216 \\
% extent_clue_dates_typemodel_rf100.log : -web-cqa
Text2KB -W-CQA & 0.6307 & 0.4978 & 0.5138 \\
% extent_cqa_dates_typemodel_rf100.log : -web-clueweb
Text2KB -W-CL & 0.6224 & 0.4928 & 0.5077 \\
\hline
\multicolumn{4}{|c|}{Effect on top of types model and dates filter improvement} \\
\hline
% THIS TELLS HOW MUCH EXTERNAL ENTITIES GIVE COMPARED TO MY OTHER IMPROVEMENTS
AQQU & 0.604 & 0.498 & 0.494\\
% baseline_typemodel_dates.log : baseline with types model +dates, but without any text-based data
Text2KB -W-CQA-CL-E &  &  & \\
% extent_dates_typemodel_rf100.log : -web-cqa-clueweb
Text2KB -W-CQA-CL & 0.6272 & 0.4920 & 0.5083 \\  % AND FEATURES GIVE THE REST
% web_cqa_clueweb_typemodel_dates.log : -external entities (Text features on top my other improvements)
Text2KB -E &  &  &  \\  % AND FEATURES GIVE THE REST

\hline
% extent_web_cqa_clueweb_dates_types_typemodel_rf100.log : everything, including type filters
Text2KB all & 0.6354 & 0.5059 & 0.5223 \\
\hline
\end{tabular}
\end{table}

As we can see ...